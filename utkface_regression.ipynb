{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xmvsLD0XWv8g"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZDtWbQi8RRl"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torchvision.transforms as T\n",
        "from transformers import CLIPModel, CLIPProcessor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "import gdown\n",
        "\n",
        "SEED = 42\n",
        "TOL_FP = 1e-12\n",
        "\n",
        "plt.rc('font', size=18)#weight='bold',\n",
        "plt.rc('legend', fontsize=18)\n",
        "plt.rc('lines', linewidth=3, markersize=9)\n",
        "mpl.rcParams['axes.grid'] = True\n",
        "\n",
        "markers = ['o','^','s','p','d']\n",
        "colors = ['b','g','r','c','m','y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlebxjIs8v-A"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9rIXrjnF9m2"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"py97/UTKFace-Cropped\")['train']\n",
        "print(f'Dataset size: {len(dataset):d}')\n",
        "sample = dataset[0] # Change the index here to check different samples\n",
        "age = (sample['__key__'].split('_')[0]).split('/')[-1]\n",
        "age = float(age)\n",
        "print(f'Age: {age:.0f}')\n",
        "sample['jpg.chip.jpg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVxZny5q8g-m"
      },
      "outputs": [],
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),           # 128 or 224, etc.\n",
        "    T.ToTensor(),                   # Convert to a torch.Tensor\n",
        "    # T.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                # std=[0.5, 0.5, 0.5]) # Example normalization\n",
        "])\n",
        "\n",
        "class UTKFaceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    UTKFace images are typically named in the format:\n",
        "      [age]_[gender]_[race]_[date].jpg\n",
        "    This dataset parses the 'age' from the filename and\n",
        "    returns (image, age) for each sample.\n",
        "    \"\"\"\n",
        "    def __init__(self, transform=transform):\n",
        "        self.dataset = load_dataset(\"py97/UTKFace-Cropped\")['train']\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        image = sample['jpg.chip.jpg']\n",
        "        age = float((sample['__key__'].split('_')[0]).split('/')[-1])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, age\n",
        "\n",
        "def get_utkface_train_test_loader(batch_size=32, test_size=0.2, seed=42):\n",
        "    \"\"\"\n",
        "    Helper function to return train and test data loaders.\n",
        "    \"\"\"\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        list(range(23708)), test_size=test_size, random_state=seed)\n",
        "\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "    test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k3WI9XG9S30"
      },
      "outputs": [],
      "source": [
        "dataset = UTKFaceDataset()\n",
        "train_loader, test_loader = get_utkface_train_test_loader(batch_size=32, test_size=0.2, seed=42)\n",
        "\n",
        "# Quick check\n",
        "for batch_images, batch_ages in train_loader:\n",
        "    print(\"Image batch shape:\", batch_images.shape)  # e.g. [32, 3, 64, 64]\n",
        "    print(\"Age batch shape:\", batch_ages.shape)      # e.g. [32]\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EctZAQfB9ASd"
      },
      "source": [
        "# Extract pre-trained representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6mqJEqbH-2l"
      },
      "source": [
        "## Compute CLIP representations\n",
        "ALERT: This inference step can take some (a lot of) time, especially on Colab! If this is a concern for you, skip this cell. You can download the precomputed representations using the Google drive URLs provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUutl1btTAjg"
      },
      "outputs": [],
      "source": [
        "# 1) Load the CLIP model and processor\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# We'll focus on the vision encoder part\n",
        "vision_encoder = clip_model.vision_model\n",
        "\n",
        "# 2) Freeze\n",
        "vision_encoder.eval()\n",
        "for param in vision_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 3) (Optional) GPU usage\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "vision_encoder.to(device)\n",
        "\n",
        "# Suppose 'dataset' yields PIL images + labels\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "all_features_clip = []\n",
        "with torch.no_grad():\n",
        "    for pil_images, _ in data_loader:\n",
        "        # 4) Use the CLIP processor or transform to get pixel_values\n",
        "        #    Usually you'd do something like:\n",
        "        inputs = processor(images=pil_images, return_tensors=\"pt\", do_rescale=False)\n",
        "        pixel_values = inputs[\"pixel_values\"].to(device)  # (B, 3, 224, 224)\n",
        "\n",
        "        # 5) Forward through CLIP's vision encoder\n",
        "        outputs = vision_encoder(pixel_values=pixel_values)\n",
        "\n",
        "        # 6) outputs has .last_hidden_state and .pooler_output\n",
        "        #    .pooler_output is usually the [CLS] embedding, shape (B, hidden_size)\n",
        "        feats = outputs.pooler_output  # shape (B, 768) for ViT-B/32\n",
        "\n",
        "        all_features_clip.append(feats.cpu())\n",
        "\n",
        "features = torch.cat(all_features_clip, dim=0)  # (N, 768)\n",
        "print(\"CLIP feature matrix shape =\", features.shape)\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "all_labels = []\n",
        "for _, labels in data_loader:\n",
        "    all_labels.append(labels)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "torch.save(all_labels, \"./utkface_labels.pt\")\n",
        "torch.save(features, \"./utkface_clipb32.pt\")\n",
        "features = torch.load(\"./utkface_clipb32.pt\")\n",
        "labels = torch.load(\"./utkface_labels.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anMHv9ku3d34"
      },
      "source": [
        "## Download CLIP representations\n",
        "- `clip_features` now contains our feature matrix $X \\in \\mathbb{R}^{n \\times d}$, consisting of $n=23708$ samples, each corresponding to a feature (a CLIP representation vector) of dimension $d=768$.\n",
        "- `labels` is a vector (`torch.Tensor`) of dimension $n=23708$ consisting of the age labels for all samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiB720VK3gxN"
      },
      "outputs": [],
      "source": [
        "clip32_id = '1YP_CF0asQb35haTCoaVpkelFsdAeQSnc'\n",
        "clip32_path = './utkface_clipb32.pt'\n",
        "lable_id = '1YPnbh1DqfkdjREkH7kfY37G7nyd1c95k'\n",
        "lable_path = './utkface_labels.pt'\n",
        "\n",
        "if not os.path.exists(clip32_path):\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={clip32_id}\", clip32_path, quiet=False)\n",
        "if not os.path.exists(lable_path):\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={lable_id}\", lable_path, quiet=False)\n",
        "\n",
        "features = torch.load(clip32_path).type(torch.float32)\n",
        "print(\"\\nCLIP feature matrix shape =\", features.shape)\n",
        "labels = torch.load(lable_path).type(torch.float32)\n",
        "print(\"Labels shape =\", labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJR-k30C6m-8"
      },
      "source": [
        "# Train-test split\n",
        "We first split the $n=23708$ samples into two subsets, one for training ($20000$ samples) and the other for testing ($3708$ samples).\n",
        "\n",
        "**Remark**: For general \"deep learning\" tasks that are highly non-convex, the entire dataset is usually splitted into 3 (instead of 2) parts:\n",
        "- **Training dataset** is usually the largest subset used to fit the model parameters. The model directly learns from this data by minimizing the training loss (e.g. via ERM).\n",
        "- **Validation dataset** is a small hold-out subset used to tune the hyperparameters (e.g., learning rate, weight decay) and to perform model selection or early stopping. The model does not learn from this data; rather, it is used to evaluate generalization performance during training.\n",
        "- **Test dataset** is used only once after the model is fully trained to report final performance. It simulates how the model generalizes (i.e. would perform in real-world deployment).\n",
        "\n",
        "For simple learning problems like linear/ridge regression, the validation set is often omitted. We will stay in this simple setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPhL7COI8oqK"
      },
      "outputs": [],
      "source": [
        "train_index, test_index = train_test_split(\n",
        "    range(labels.shape[0]), test_size=3708, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(\"Training set size =\", len(train_index))\n",
        "print(\"Test set size =\", len(test_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieACh40hBfcy"
      },
      "source": [
        "# Test risk (an approximation of population risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35wJcGxlBlRp"
      },
      "outputs": [],
      "source": [
        "fea_test, lab_test = features[test_index], labels[test_index]\n",
        "\n",
        "def test_risk(prediction):\n",
        "    # Define the test risk (in square loss) below (as an approximation of the population risk)\n",
        "    error = (prediction - lab_test)\n",
        "    risk = (error ** 2).mean()\n",
        "    return risk.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlD1ngDEJHdG"
      },
      "source": [
        "# Extra credit I: linear regression\n",
        "Implement a linear regression predictor that takes the number of i.i.d. training samples $768 < n \\le 20000$ to be used in ERM as inputs and outputs the ERM minimizer $\\hat{\\theta}$ as a (lambda) function $f(x) = x^\\top \\hat{\\theta}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0AytdgGPWt1"
      },
      "outputs": [],
      "source": [
        "def linear_regression(n_train):\n",
        "    fea_train, lab_train = features[train_index[:n_train]], labels[train_index[:n_train]]\n",
        "    # Implement linear regression below\n",
        "    theta_hat = np.linalg.inv(fea_train.T @ fea_train) @ fea_train.T @ lab_train\n",
        "    prediction = lambda x: x @ theta_hat\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZbyEB98CNpn"
      },
      "source": [
        "## Scaling law for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g444RANpS6-w"
      },
      "outputs": [],
      "source": [
        "n_trains = torch.arange(2000, 20001, 2000)\n",
        "lr_risks = torch.zeros(n_trains.shape)\n",
        "for i, n_train in enumerate(n_trains):\n",
        "    prediction = linear_regression(n_train)\n",
        "    lr_risks[i] = test_risk(prediction)\n",
        "    print(f'Test risk with n={n_train:d} samples: ', lr_risks[i].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZOI1IUWEn37"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(n_trains, lr_risks, 'o:', label='Test risk')\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Test risk')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS12bozB6TDT"
      },
      "source": [
        "# Extra credit II: ridge regression\n",
        "\n",
        "Now, implement a ridge regression predictor that takes\n",
        "\n",
        "1. the number of i.i.d. training samples $768 < n \\le 20000$ to be used in ERM and\n",
        "2. a ridge parameter $\\lambda = 10$ by default\n",
        "\n",
        "as inputs and outputs the ridge regression minimizer $\\hat{\\theta}$ as a (lambda) function $f(x) = x^\\top \\hat{\\theta}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZW5fS1_TDjc"
      },
      "outputs": [],
      "source": [
        "ridge = 10\n",
        "def ridge_regression(n_train, ridge=ridge):\n",
        "    fea_train, lab_train = features[train_index[:n_train]], labels[train_index[:n_train]]\n",
        "    # Implement ridge regression below\n",
        "    n, d = fea_train.shape\n",
        "    theta_hat = np.linalg.inv(fea_train.T @ fea_train + n * ridge * np.eye(d)) @ fea_train.T @ lab_train\n",
        "    prediction = lambda x: x @ theta_hat\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnoUn0HrHtGG"
      },
      "source": [
        "## Scaling law for ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H4mijiSHs53"
      },
      "outputs": [],
      "source": [
        "n_trains = torch.arange(2000, 20001, 2000)\n",
        "ridges = [100, 10, 1, 1e-1]\n",
        "rr_risks = dict()\n",
        "for ridge in ridges:\n",
        "    rr_risks_ = torch.zeros(n_trains.shape)\n",
        "    for i, n_train in enumerate(n_trains):\n",
        "        prediction = ridge_regression(n_train, ridge=ridge)\n",
        "        rr_risks_[i] = test_risk(prediction)\n",
        "        print(f'Test risk with ridge={ridge:.0e}, n={n_train:d} samples: ', rr_risks_[i].item())\n",
        "    rr_risks[ridge] = rr_risks_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf8BAFK76Wi5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(n_trains, lr_risks, 'o:', label='Linear regression')\n",
        "for ridge, rr_risks_ in rr_risks.items():\n",
        "    plt.plot(n_trains, rr_risks_, 'o:', label=f'Ridge regression $\\lambda={ridge}$')\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Test risk')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csC2FQwTI_uq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}